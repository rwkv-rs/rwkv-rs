[package]
name = "rwkv-infer"
version = "0.1.0"
edition = "2024"
description = "Work-in-progress inference runtime hooking RWKV language models to Tokio backends"
license = "Apache-2.0"

[dependencies]
tokio = { workspace = true }
tokio-stream = { workspace = true }
serde = { workspace = true, features = ["derive"] }
sonic-rs = { workspace = true }
toml = { workspace = true }
uuid = { workspace = true }

# HTTP server (OpenAI-compatible)
axum = { workspace = true }
tower-http = { workspace = true }

# Inference utilities
dashmap = { workspace = true }
once_cell = { workspace = true }
log = { workspace = true }
thiserror = { workspace = true }

# Optional tokenizer for text endpoints (RWKV vocab)
rwkv-data = { path = "../rwkv-data" }
rwkv-config = { path = "../rwkv-config" }
rwkv-trace = { path = "../rwkv-trace", optional = true }
clia-tracing-config = { workspace = true }
iceoryx2 = { version = "0.8.1", optional = true, features = ["libc_platform"] }

[features]
default = ["http"]
http = []
ipc-iceoryx2 = ["dep:iceoryx2"]
trace-lite = ["dep:rwkv-trace", "rwkv-trace/tracy"]
trace-full = ["trace-lite"]

[dev-dependencies]
tower = { workspace = true }
