[package]
name = "rwkv-infer"
version = "0.1.0"
edition = "2024"
description = "Work-in-progress inference runtime hooking RWKV language models to Tokio backends"
license = "Apache-2.0"

[dependencies]
tokio = { workspace = true }
tokio-stream = { workspace = true }
serde = { workspace = true, features = ["derive"] }
sonic-rs = { workspace = true }
toml = { workspace = true }
uuid = { workspace = true }

# HTTP server (OpenAI-compatible)
axum = { workspace = true }
tower-http = { workspace = true, features = ["trace"] }

# Inference utilities
dashmap = { workspace = true }
once_cell = { workspace = true }
log = { workspace = true }
thiserror = { workspace = true }
tracing = { workspace = true, optional = true }
nvtx = { workspace = true, optional = true }

# Optional tokenizer for text endpoints (RWKV vocab)
rwkv-data = { path = "../rwkv-data" }
rwkv-config = { path = "../rwkv-config" }
rwkv-bench = { path = "../rwkv-bench", default-features = false, optional = true }
clia-tracing-config = { workspace = true }
iceoryx2 = { workspace = true, optional = true }

[features]
default = ["http"]
http = []
ipc-iceoryx2 = ["dep:iceoryx2"]
trace = ["dep:tracing", "dep:rwkv-bench", "rwkv-bench/trace"]
nsys = ["trace", "dep:nvtx"]

[dev-dependencies]
tower = { workspace = true }
